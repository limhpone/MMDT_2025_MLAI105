{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis and Deployment Walkthrough\n",
    "\n",
    "This notebook explains our trained BiLSTM model analysis system for real-world Myanmar news article classification and interpretation.\n",
    "\n",
    "## Environment Setup\n",
    "**Conda Environment:** nlp  \n",
    "**Purpose:** Deploy trained model for analyzing Myanmar news articles in production\n",
    "\n",
    "## Analysis Pipeline Overview\n",
    "```\n",
    "Raw Article Text ‚Üí Preprocessing ‚Üí Tokenization ‚Üí Model Prediction ‚Üí Analysis Report\n",
    "```\n",
    "\n",
    "**Output:** Detailed classification with confidence scores, reasoning, and visual reports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Loading and Initialization\n",
    "\n",
    "### Production Model Setup\n",
    "Load the trained BiLSTM model and all required artifacts for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "class MyanmarNewsAnalyzer:\n",
    "    \"\"\"\n",
    "    Production deployment class for Myanmar news sentiment analysis.\n",
    "    \n",
    "    Capabilities:\n",
    "    - Load trained BiLSTM model and artifacts\n",
    "    - Process raw Myanmar text articles\n",
    "    - Generate detailed classification reports\n",
    "    - Provide confidence scores and reasoning\n",
    "    - Create visual analysis outputs\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_dir):\n",
    "        \"\"\"\n",
    "        Initialize analyzer with trained model artifacts.\n",
    "        \n",
    "        Args:\n",
    "            model_dir (str): Directory containing model files:\n",
    "                - bilstm_model.h5: Trained Keras model\n",
    "                - tokenizer.pickle: Fitted tokenizer\n",
    "                - model_params.pickle: Model configuration\n",
    "        \"\"\"\n",
    "        self.model_dir = model_dir\n",
    "        self.model = None\n",
    "        self.tokenizer = None\n",
    "        self.model_params = None\n",
    "        self.myword_tokenizer = None\n",
    "        \n",
    "        # Label mappings\n",
    "        self.label_mapping = {\n",
    "            0: 'neutral',    # DVB - opposition/neutral\n",
    "            1: 'red',        # Khitthit - critical\n",
    "            2: 'green'       # Myawady - government-friendly\n",
    "        }\n",
    "        \n",
    "        self.label_descriptions = {\n",
    "            'neutral': 'Opposition/Neutral perspective (characteristic of DVB News)',\n",
    "            'red': 'Critical/Independent perspective (characteristic of Khitthit News)',\n",
    "            'green': 'Government-friendly perspective (characteristic of Myawady News)'\n",
    "        }\n",
    "        \n",
    "        # Initialize components\n",
    "        self._load_model_artifacts()\n",
    "        self._initialize_myanmar_tokenizer()\n",
    "    \n",
    "    def _load_model_artifacts(self):\n",
    "        \"\"\"\n",
    "        Load all model artifacts from disk.\n",
    "        \n",
    "        Critical for production deployment:\n",
    "        - Model weights and architecture\n",
    "        - Vocabulary mapping (tokenizer)\n",
    "        - Model hyperparameters\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Load trained model\n",
    "            model_path = os.path.join(self.model_dir, 'bilstm_model.h5')\n",
    "            if os.path.exists(model_path):\n",
    "                self.model = tf.keras.models.load_model(model_path)\n",
    "                print(f\"‚úÖ Model loaded: {model_path}\")\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
    "            \n",
    "            # Load tokenizer\n",
    "            tokenizer_path = os.path.join(self.model_dir, 'tokenizer.pickle')\n",
    "            if os.path.exists(tokenizer_path):\n",
    "                with open(tokenizer_path, 'rb') as f:\n",
    "                    self.tokenizer = pickle.load(f)\n",
    "                print(f\"‚úÖ Tokenizer loaded: vocabulary size {len(self.tokenizer.word_index)}\")\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"Tokenizer file not found: {tokenizer_path}\")\n",
    "            \n",
    "            # Load model parameters\n",
    "            params_path = os.path.join(self.model_dir, 'model_params.pickle')\n",
    "            if os.path.exists(params_path):\n",
    "                with open(params_path, 'rb') as f:\n",
    "                    self.model_params = pickle.load(f)\n",
    "                print(f\"‚úÖ Model parameters loaded: {self.model_params}\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è  Model parameters file not found, using defaults\")\n",
    "                self.model_params = {\n",
    "                    'max_length': 500,\n",
    "                    'vocab_size': 10000\n",
    "                }\n",
    "            \n",
    "            print(f\"\\nüöÄ Myanmar News Analyzer initialized successfully!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading model artifacts: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _initialize_myanmar_tokenizer(self):\n",
    "        \"\"\"\n",
    "        Initialize MyWord tokenizer for processing raw text.\n",
    "        \n",
    "        This is needed to convert raw articles into the same token format\n",
    "        that was used during training.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Import MyWord tokenizer\n",
    "            from myword import MyWord\n",
    "            self.myword_tokenizer = MyWord()\n",
    "            print(f\"‚úÖ MyWord tokenizer initialized\")\n",
    "        except ImportError:\n",
    "            print(f\"‚ö†Ô∏è  MyWord tokenizer not available, using fallback tokenization\")\n",
    "            self.myword_tokenizer = None\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess raw Myanmar text for model input.\n",
    "        \n",
    "        Applies the same preprocessing pipeline used during training:\n",
    "        1. Unicode normalization\n",
    "        2. Character cleaning\n",
    "        3. Myanmar-specific text formatting\n",
    "        \n",
    "        Args:\n",
    "            text (str): Raw Myanmar article text\n",
    "        \n",
    "        Returns:\n",
    "            str: Cleaned text ready for tokenization\n",
    "        \"\"\"\n",
    "        if not text or not isinstance(text, str):\n",
    "            return \"\"\n",
    "        \n",
    "        # Unicode normalization (critical for Myanmar)\n",
    "        text = unicodedata.normalize('NFC', text)\n",
    "        \n",
    "        # Clean unwanted characters while preserving Myanmar script\n",
    "        allowed_pattern = r'[^\\u1000-\\u109F\\u0020-\\u007E\\u00A0-\\u00FF\\uAA60-\\uAA7F\\uA9E0-\\uA9FF\\u2000-\\u206F\\u2070-\\u209F\\u20A0-\\u20CF]'\n",
    "        text = re.sub(allowed_pattern, ' ', text)\n",
    "        \n",
    "        # Whitespace standardization\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        text = text.strip()\n",
    "        \n",
    "        # Clean excessive punctuation\n",
    "        text = re.sub(r'[,.!?;:]{2,}', '.', text)\n",
    "        text = re.sub(r'\\.{3,}', '...', text)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def tokenize_text(self, text):\n",
    "        \"\"\"\n",
    "        Tokenize Myanmar text using the same method as training.\n",
    "        \n",
    "        Args:\n",
    "            text (str): Preprocessed Myanmar text\n",
    "        \n",
    "        Returns:\n",
    "            list: Myanmar word tokens\n",
    "        \"\"\"\n",
    "        if self.myword_tokenizer:\n",
    "            try:\n",
    "                tokens = self.myword_tokenizer.segment(text)\n",
    "                return [token.strip() for token in tokens if token.strip()]\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è  MyWord tokenization failed: {e}, using fallback\")\n",
    "        \n",
    "        # Fallback tokenization\n",
    "        tokens = text.split()\n",
    "        refined_tokens = []\n",
    "        for token in tokens:\n",
    "            subtokens = re.findall(r'[\\u1000-\\u109F]+|[a-zA-Z0-9]+|[.,!?]', token)\n",
    "            refined_tokens.extend(subtokens)\n",
    "        \n",
    "        return [token for token in refined_tokens if token.strip()]\n",
    "\n",
    "print(\"‚úÖ Myanmar News Analyzer class implementation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Article Analysis Pipeline\n",
    "\n",
    "### End-to-End Classification Process\n",
    "Complete pipeline from raw article text to detailed sentiment classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def analyze_article(self, article_text, article_title=\"\"):\n",
    "        \"\"\"\n",
    "        Analyze a single Myanmar news article.\n",
    "        \n",
    "        Complete analysis pipeline:\n",
    "        1. Text preprocessing\n",
    "        2. Myanmar tokenization\n",
    "        3. Sequence preparation\n",
    "        4. Model prediction\n",
    "        5. Results interpretation\n",
    "        \n",
    "        Args:\n",
    "            article_text (str): Main article content\n",
    "            article_title (str): Article title (optional)\n",
    "        \n",
    "        Returns:\n",
    "            dict: Comprehensive analysis results\n",
    "        \"\"\"\n",
    "        if not article_text:\n",
    "            return {'error': 'No article text provided'}\n",
    "        \n",
    "        # Step 1: Combine title and content\n",
    "        full_text = f\"{article_title} {article_text}\".strip()\n",
    "        \n",
    "        # Step 2: Preprocess text\n",
    "        preprocessed_text = self.preprocess_text(full_text)\n",
    "        \n",
    "        if len(preprocessed_text) < 20:\n",
    "            return {'error': 'Article too short for meaningful analysis'}\n",
    "        \n",
    "        # Step 3: Tokenize\n",
    "        tokens = self.tokenize_text(preprocessed_text)\n",
    "        \n",
    "        if len(tokens) < 5:\n",
    "            return {'error': 'Insufficient tokens for classification'}\n",
    "        \n",
    "        # Step 4: Convert to model input format\n",
    "        token_text = ' '.join(tokens)  # Space-separated tokens\n",
    "        sequence = self.tokenizer.texts_to_sequences([token_text])\n",
    "        \n",
    "        # Step 5: Pad sequence\n",
    "        max_length = self.model_params.get('max_length', 500)\n",
    "        padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "            sequence, maxlen=max_length, padding='post'\n",
    "        )\n",
    "        \n",
    "        # Step 6: Get model prediction\n",
    "        prediction_proba = self.model.predict(padded_sequence, verbose=0)\n",
    "        predicted_class = np.argmax(prediction_proba[0])\n",
    "        confidence_scores = prediction_proba[0]\n",
    "        \n",
    "        # Step 7: Interpret results\n",
    "        predicted_label = self.label_mapping[predicted_class]\n",
    "        confidence = float(confidence_scores[predicted_class])\n",
    "        \n",
    "        # Calculate relative confidence (how much more confident than second choice)\n",
    "        sorted_scores = np.sort(confidence_scores)[::-1]\n",
    "        relative_confidence = float(sorted_scores[0] - sorted_scores[1])\n",
    "        \n",
    "        # Determine confidence level\n",
    "        if confidence >= 0.8:\n",
    "            confidence_level = 'Very High'\n",
    "        elif confidence >= 0.6:\n",
    "            confidence_level = 'High'\n",
    "        elif confidence >= 0.4:\n",
    "            confidence_level = 'Medium'\n",
    "        else:\n",
    "            confidence_level = 'Low'\n",
    "        \n",
    "        # Create analysis results\n",
    "        analysis_result = {\n",
    "            'input_info': {\n",
    "                'title': article_title,\n",
    "                'content_length': len(article_text),\n",
    "                'preprocessed_length': len(preprocessed_text),\n",
    "                'token_count': len(tokens),\n",
    "                'analysis_timestamp': datetime.now().isoformat()\n",
    "            },\n",
    "            'classification': {\n",
    "                'predicted_class': int(predicted_class),\n",
    "                'predicted_label': predicted_label,\n",
    "                'confidence': confidence,\n",
    "                'confidence_level': confidence_level,\n",
    "                'relative_confidence': relative_confidence\n",
    "            },\n",
    "            'detailed_scores': {\n",
    "                'neutral': float(confidence_scores[0]),\n",
    "                'red': float(confidence_scores[1]),\n",
    "                'green': float(confidence_scores[2])\n",
    "            },\n",
    "            'interpretation': {\n",
    "                'description': self.label_descriptions[predicted_label],\n",
    "                'reasoning': self._generate_reasoning(predicted_label, confidence, tokens),\n",
    "                'alternative_possibilities': self._get_alternative_analysis(confidence_scores)\n",
    "            },\n",
    "            'text_analysis': {\n",
    "                'sample_tokens': tokens[:20],  # First 20 tokens for inspection\n",
    "                'token_statistics': self._analyze_token_composition(tokens)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return analysis_result\n",
    "    \n",
    "    def _generate_reasoning(self, predicted_label, confidence, tokens):\n",
    "        \"\"\"\n",
    "        Generate human-readable reasoning for the classification.\n",
    "        \n",
    "        Provides contextual explanation of why the model made this prediction\n",
    "        based on confidence levels and label characteristics.\n",
    "        \"\"\"\n",
    "        reasoning_templates = {\n",
    "            'neutral': {\n",
    "                'high': 'The article exhibits characteristics typical of opposition or neutral reporting, similar to DVB News style. Language patterns suggest balanced or critical perspective toward current events.',\n",
    "                'medium': 'The article shows moderate alignment with neutral/opposition reporting style, though with some mixed signals that prevent higher confidence.',\n",
    "                'low': 'The article has some characteristics of neutral reporting, but the classification is uncertain due to conflicting linguistic patterns.'\n",
    "            },\n",
    "            'red': {\n",
    "                'high': 'The article strongly exhibits critical/independent journalism characteristics, similar to Khitthit News. Language suggests investigative or questioning approach to reporting.',\n",
    "                'medium': 'The article shows moderate alignment with critical journalism style, with some elements suggesting independent reporting perspective.',\n",
    "                'low': 'The article has some critical journalism elements, but the classification confidence is limited due to mixed stylistic signals.'\n",
    "            },\n",
    "            'green': {\n",
    "                'high': 'The article clearly demonstrates government-friendly reporting characteristics, similar to Myawady News. Language patterns suggest supportive or official perspective.',\n",
    "                'medium': 'The article shows moderate alignment with government-friendly reporting, though with some elements that introduce uncertainty.',\n",
    "                'low': 'The article has some government-friendly characteristics, but mixed signals prevent confident classification.'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Determine confidence category\n",
    "        if confidence >= 0.7:\n",
    "            conf_category = 'high'\n",
    "        elif confidence >= 0.5:\n",
    "            conf_category = 'medium'\n",
    "        else:\n",
    "            conf_category = 'low'\n",
    "        \n",
    "        base_reasoning = reasoning_templates[predicted_label][conf_category]\n",
    "        \n",
    "        # Add token-based insights\n",
    "        token_insight = f\" The analysis was based on {len(tokens)} Myanmar language tokens extracted from the article.\"\n",
    "        \n",
    "        return base_reasoning + token_insight\n",
    "    \n",
    "    def _get_alternative_analysis(self, confidence_scores):\n",
    "        \"\"\"\n",
    "        Analyze alternative classifications and their probabilities.\n",
    "        \n",
    "        Helps understand model uncertainty and alternative interpretations.\n",
    "        \"\"\"\n",
    "        # Get sorted predictions\n",
    "        sorted_indices = np.argsort(confidence_scores)[::-1]\n",
    "        \n",
    "        alternatives = []\n",
    "        for i, idx in enumerate(sorted_indices):\n",
    "            if i == 0:  # Skip the primary prediction\n",
    "                continue\n",
    "            \n",
    "            label = self.label_mapping[idx]\n",
    "            score = float(confidence_scores[idx])\n",
    "            \n",
    "            if score > 0.1:  # Only include meaningful alternatives\n",
    "                alternatives.append({\n",
    "                    'label': label,\n",
    "                    'probability': score,\n",
    "                    'description': self.label_descriptions[label]\n",
    "                })\n",
    "        \n",
    "        return alternatives\n",
    "    \n",
    "    def _analyze_token_composition(self, tokens):\n",
    "        \"\"\"\n",
    "        Analyze the composition of tokens for insight into text characteristics.\n",
    "        \"\"\"\n",
    "        myanmar_tokens = [t for t in tokens if re.search(r'[\\u1000-\\u109F]', t)]\n",
    "        english_tokens = [t for t in tokens if re.search(r'[a-zA-Z]', t)]\n",
    "        number_tokens = [t for t in tokens if re.search(r'[0-9]', t)]\n",
    "        \n",
    "        return {\n",
    "            'total_tokens': len(tokens),\n",
    "            'myanmar_tokens': len(myanmar_tokens),\n",
    "            'english_tokens': len(english_tokens),\n",
    "            'number_tokens': len(number_tokens),\n",
    "            'myanmar_ratio': len(myanmar_tokens) / len(tokens) if tokens else 0,\n",
    "            'avg_token_length': np.mean([len(t) for t in tokens]) if tokens else 0\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Article analysis pipeline implementation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Batch Analysis and Reporting\n",
    "\n",
    "### Multi-Article Analysis System\n",
    "Process multiple articles and generate comprehensive analysis reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def analyze_multiple_articles(self, articles_dir, output_dir=None):\n",
    "        \"\"\"\n",
    "        Analyze multiple articles from a directory.\n",
    "        \n",
    "        Process:\n",
    "        1. Load all .txt files from directory\n",
    "        2. Analyze each article individually\n",
    "        3. Generate aggregate statistics\n",
    "        4. Create visual analysis reports\n",
    "        5. Save detailed results\n",
    "        \n",
    "        Args:\n",
    "            articles_dir (str): Directory containing article .txt files\n",
    "            output_dir (str): Directory to save analysis results\n",
    "        \n",
    "        Returns:\n",
    "            dict: Batch analysis results\n",
    "        \"\"\"\n",
    "        if output_dir is None:\n",
    "            output_dir = f\"analysis_output_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "        \n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Find all text files\n",
    "        article_files = [f for f in os.listdir(articles_dir) if f.endswith('.txt')]\n",
    "        \n",
    "        if not article_files:\n",
    "            return {'error': f'No .txt files found in {articles_dir}'}\n",
    "        \n",
    "        print(f\"\\nüìÇ Analyzing {len(article_files)} articles from: {articles_dir}\")\n",
    "        print(f\"üìÅ Output directory: {output_dir}\")\n",
    "        \n",
    "        # Analyze each article\n",
    "        analysis_results = []\n",
    "        for i, filename in enumerate(article_files):\n",
    "            file_path = os.path.join(articles_dir, filename)\n",
    "            \n",
    "            try:\n",
    "                # Read article\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    article_text = f.read().strip()\n",
    "                \n",
    "                if not article_text:\n",
    "                    print(f\"   ‚ö†Ô∏è  Skipping empty file: {filename}\")\n",
    "                    continue\n",
    "                \n",
    "                # Analyze article\n",
    "                result = self.analyze_article(article_text, article_title=filename)\n",
    "                \n",
    "                if 'error' in result:\n",
    "                    print(f\"   ‚ùå Error analyzing {filename}: {result['error']}\")\n",
    "                    continue\n",
    "                \n",
    "                # Add file information\n",
    "                result['file_info'] = {\n",
    "                    'filename': filename,\n",
    "                    'file_path': file_path,\n",
    "                    'file_index': i\n",
    "                }\n",
    "                \n",
    "                analysis_results.append(result)\n",
    "                \n",
    "                # Progress update\n",
    "                predicted_label = result['classification']['predicted_label']\n",
    "                confidence = result['classification']['confidence']\n",
    "                print(f\"   ‚úÖ {filename}: {predicted_label} ({confidence:.3f})\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå Error processing {filename}: {e}\")\n",
    "        \n",
    "        if not analysis_results:\n",
    "            return {'error': 'No articles were successfully analyzed'}\n",
    "        \n",
    "        # Generate batch statistics\n",
    "        batch_stats = self._generate_batch_statistics(analysis_results)\n",
    "        \n",
    "        # Create visualizations\n",
    "        self._create_analysis_visualizations(analysis_results, batch_stats, output_dir)\n",
    "        \n",
    "        # Save detailed results\n",
    "        results_file = os.path.join(output_dir, 'detailed_analysis.json')\n",
    "        with open(results_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump({\n",
    "                'analysis_info': {\n",
    "                    'timestamp': datetime.now().isoformat(),\n",
    "                    'articles_processed': len(analysis_results),\n",
    "                    'source_directory': articles_dir,\n",
    "                    'output_directory': output_dir\n",
    "                },\n",
    "                'batch_statistics': batch_stats,\n",
    "                'individual_results': analysis_results\n",
    "            }, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Batch analysis complete:\")\n",
    "        print(f\"   Articles processed: {len(analysis_results)}\")\n",
    "        print(f\"   Results saved: {results_file}\")\n",
    "        print(f\"   Visualizations saved: {output_dir}/\")\n",
    "        \n",
    "        return {\n",
    "            'batch_statistics': batch_stats,\n",
    "            'individual_results': analysis_results,\n",
    "            'output_directory': output_dir\n",
    "        }\n",
    "    \n",
    "    def _generate_batch_statistics(self, analysis_results):\n",
    "        \"\"\"\n",
    "        Generate aggregate statistics from batch analysis.\n",
    "        \n",
    "        Statistics include:\n",
    "        - Label distribution\n",
    "        - Confidence score analysis\n",
    "        - Text characteristics\n",
    "        - Quality metrics\n",
    "        \"\"\"\n",
    "        # Extract key metrics\n",
    "        labels = [r['classification']['predicted_label'] for r in analysis_results]\n",
    "        confidences = [r['classification']['confidence'] for r in analysis_results]\n",
    "        token_counts = [r['input_info']['token_count'] for r in analysis_results]\n",
    "        \n",
    "        # Label distribution\n",
    "        from collections import Counter\n",
    "        label_counts = Counter(labels)\n",
    "        \n",
    "        # Confidence analysis by label\n",
    "        confidence_by_label = {}\n",
    "        for label in ['neutral', 'red', 'green']:\n",
    "            label_confidences = [r['classification']['confidence'] \n",
    "                               for r in analysis_results \n",
    "                               if r['classification']['predicted_label'] == label]\n",
    "            if label_confidences:\n",
    "                confidence_by_label[label] = {\n",
    "                    'count': len(label_confidences),\n",
    "                    'mean_confidence': np.mean(label_confidences),\n",
    "                    'std_confidence': np.std(label_confidences),\n",
    "                    'min_confidence': np.min(label_confidences),\n",
    "                    'max_confidence': np.max(label_confidences)\n",
    "                }\n",
    "        \n",
    "        return {\n",
    "            'total_articles': len(analysis_results),\n",
    "            'label_distribution': dict(label_counts),\n",
    "            'label_percentages': {label: count/len(analysis_results)*100 \n",
    "                                for label, count in label_counts.items()},\n",
    "            'confidence_statistics': {\n",
    "                'overall_mean': np.mean(confidences),\n",
    "                'overall_std': np.std(confidences),\n",
    "                'by_label': confidence_by_label\n",
    "            },\n",
    "            'text_statistics': {\n",
    "                'mean_token_count': np.mean(token_counts),\n",
    "                'std_token_count': np.std(token_counts),\n",
    "                'min_token_count': np.min(token_counts),\n",
    "                'max_token_count': np.max(token_counts)\n",
    "            },\n",
    "            'quality_metrics': {\n",
    "                'high_confidence_count': sum(1 for c in confidences if c >= 0.8),\n",
    "                'medium_confidence_count': sum(1 for c in confidences if 0.5 <= c < 0.8),\n",
    "                'low_confidence_count': sum(1 for c in confidences if c < 0.5),\n",
    "                'avg_relative_confidence': np.mean([r['classification']['relative_confidence'] \n",
    "                                                  for r in analysis_results])\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _create_analysis_visualizations(self, analysis_results, batch_stats, output_dir):\n",
    "        \"\"\"\n",
    "        Create comprehensive visualization reports.\n",
    "        \n",
    "        Generates:\n",
    "        1. Label distribution pie chart\n",
    "        2. Confidence score distributions\n",
    "        3. Confidence by label box plots\n",
    "        4. Text length analysis\n",
    "        \"\"\"\n",
    "        # Set up the plotting style\n",
    "        plt.style.use('default')\n",
    "        sns.set_palette(\"Set2\")\n",
    "        \n",
    "        # Create a comprehensive figure\n",
    "        fig = plt.figure(figsize=(16, 12))\n",
    "        \n",
    "        # 1. Label Distribution Pie Chart\n",
    "        ax1 = plt.subplot(2, 3, 1)\n",
    "        labels = list(batch_stats['label_distribution'].keys())\n",
    "        counts = list(batch_stats['label_distribution'].values())\n",
    "        colors = ['#FFB6C1', '#FF6B6B', '#90EE90']  # Light colors for neutral, red, green\n",
    "        \n",
    "        wedges, texts, autotexts = ax1.pie(counts, labels=labels, autopct='%1.1f%%', \n",
    "                                          colors=colors, startangle=90)\n",
    "        ax1.set_title('Article Classification Distribution', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        # 2. Confidence Score Histogram\n",
    "        ax2 = plt.subplot(2, 3, 2)\n",
    "        confidences = [r['classification']['confidence'] for r in analysis_results]\n",
    "        ax2.hist(confidences, bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        ax2.set_xlabel('Confidence Score')\n",
    "        ax2.set_ylabel('Number of Articles')\n",
    "        ax2.set_title('Confidence Score Distribution', fontsize=12, fontweight='bold')\n",
    "        ax2.axvline(np.mean(confidences), color='red', linestyle='--', \n",
    "                    label=f'Mean: {np.mean(confidences):.3f}')\n",
    "        ax2.legend()\n",
    "        \n",
    "        # 3. Confidence by Label Box Plot\n",
    "        ax3 = plt.subplot(2, 3, 3)\n",
    "        label_conf_data = []\n",
    "        label_names = []\n",
    "        for label in ['neutral', 'red', 'green']:\n",
    "            label_confidences = [r['classification']['confidence'] \n",
    "                               for r in analysis_results \n",
    "                               if r['classification']['predicted_label'] == label]\n",
    "            if label_confidences:\n",
    "                label_conf_data.append(label_confidences)\n",
    "                label_names.append(label)\n",
    "        \n",
    "        if label_conf_data:\n",
    "            ax3.boxplot(label_conf_data, labels=label_names)\n",
    "            ax3.set_ylabel('Confidence Score')\n",
    "            ax3.set_title('Confidence by Label', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        # 4. Token Count Distribution\n",
    "        ax4 = plt.subplot(2, 3, 4)\n",
    "        token_counts = [r['input_info']['token_count'] for r in analysis_results]\n",
    "        ax4.hist(token_counts, bins=15, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "        ax4.set_xlabel('Token Count')\n",
    "        ax4.set_ylabel('Number of Articles')\n",
    "        ax4.set_title('Article Length Distribution', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        # 5. Confidence vs Token Count Scatter\n",
    "        ax5 = plt.subplot(2, 3, 5)\n",
    "        confidences = [r['classification']['confidence'] for r in analysis_results]\n",
    "        token_counts = [r['input_info']['token_count'] for r in analysis_results]\n",
    "        labels = [r['classification']['predicted_label'] for r in analysis_results]\n",
    "        \n",
    "        # Color by label\n",
    "        color_map = {'neutral': 'pink', 'red': 'red', 'green': 'green'}\n",
    "        colors = [color_map[label] for label in labels]\n",
    "        \n",
    "        ax5.scatter(token_counts, confidences, c=colors, alpha=0.6)\n",
    "        ax5.set_xlabel('Token Count')\n",
    "        ax5.set_ylabel('Confidence Score')\n",
    "        ax5.set_title('Confidence vs Article Length', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        # 6. Summary Statistics Text\n",
    "        ax6 = plt.subplot(2, 3, 6)\n",
    "        ax6.axis('off')\n",
    "        \n",
    "        stats_text = f\"\"\"\n",
    "        Analysis Summary\n",
    "        ________________\n",
    "        \n",
    "        Total Articles: {batch_stats['total_articles']}\n",
    "        \n",
    "        Label Distribution:\n",
    "        ‚Ä¢ Neutral: {batch_stats['label_distribution'].get('neutral', 0)} \n",
    "          ({batch_stats['label_percentages'].get('neutral', 0):.1f}%)\n",
    "        ‚Ä¢ Red: {batch_stats['label_distribution'].get('red', 0)} \n",
    "          ({batch_stats['label_percentages'].get('red', 0):.1f}%)\n",
    "        ‚Ä¢ Green: {batch_stats['label_distribution'].get('green', 0)} \n",
    "          ({batch_stats['label_percentages'].get('green', 0):.1f}%)\n",
    "        \n",
    "        Confidence:\n",
    "        ‚Ä¢ Mean: {batch_stats['confidence_statistics']['overall_mean']:.3f}\n",
    "        ‚Ä¢ Std: {batch_stats['confidence_statistics']['overall_std']:.3f}\n",
    "        \n",
    "        Quality:\n",
    "        ‚Ä¢ High Confidence (‚â•0.8): {batch_stats['quality_metrics']['high_confidence_count']}\n",
    "        ‚Ä¢ Medium Confidence: {batch_stats['quality_metrics']['medium_confidence_count']}\n",
    "        ‚Ä¢ Low Confidence (<0.5): {batch_stats['quality_metrics']['low_confidence_count']}\n",
    "        \"\"\"\n",
    "        \n",
    "        ax6.text(0.1, 0.9, stats_text, transform=ax6.transAxes, fontsize=10,\n",
    "                verticalalignment='top', fontfamily='monospace')\n",
    "        \n",
    "        # Add main title\n",
    "        fig.suptitle('Myanmar News Classification Analysis Report', \n",
    "                    fontsize=16, fontweight='bold', y=0.98)\n",
    "        \n",
    "        # Adjust layout and save\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.93)\n",
    "        \n",
    "        # Save the visualization\n",
    "        viz_path = os.path.join(output_dir, 'visual_analysis_report.png')\n",
    "        plt.savefig(viz_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"   üìä Visualization saved: {viz_path}\")\n",
    "\n",
    "print(\"‚úÖ Batch analysis and reporting implementation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Production Deployment Example\n",
    "\n",
    "### Complete Analysis Workflow\n",
    "Demonstration of the full analysis system in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_myanmar_news_analysis(model_dir, test_articles_dir):\n",
    "    \"\"\"\n",
    "    Complete production analysis workflow demonstration.\n",
    "    \n",
    "    This function shows how to:\n",
    "    1. Initialize the analyzer with trained model\n",
    "    2. Process individual articles\n",
    "    3. Run batch analysis on multiple articles\n",
    "    4. Generate comprehensive reports\n",
    "    \n",
    "    Args:\n",
    "        model_dir (str): Directory with trained model artifacts\n",
    "        test_articles_dir (str): Directory with test articles (.txt files)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Complete analysis results\n",
    "    \"\"\"\n",
    "    print(f\"üá≤üá≤ Myanmar News Analysis System\")\n",
    "    print(f\"=\" * 50)\n",
    "    \n",
    "    # Step 1: Initialize analyzer\n",
    "    print(f\"\\nüì• Step 1: Loading trained model...\")\n",
    "    try:\n",
    "        analyzer = MyanmarNewsAnalyzer(model_dir)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to initialize analyzer: {e}\")\n",
    "        return {'error': f'Initialization failed: {e}'}\n",
    "    \n",
    "    # Step 2: Single article demonstration (if any article exists)\n",
    "    print(f\"\\nüîç Step 2: Single article analysis demonstration...\")\n",
    "    sample_files = [f for f in os.listdir(test_articles_dir) if f.endswith('.txt')][:1]\n",
    "    \n",
    "    if sample_files:\n",
    "        sample_file = os.path.join(test_articles_dir, sample_files[0])\n",
    "        with open(sample_file, 'r', encoding='utf-8') as f:\n",
    "            sample_text = f.read().strip()\n",
    "        \n",
    "        if sample_text:\n",
    "            print(f\"   üìÑ Analyzing sample article: {sample_files[0]}\")\n",
    "            single_result = analyzer.analyze_article(sample_text, sample_files[0])\n",
    "            \n",
    "            if 'error' not in single_result:\n",
    "                classification = single_result['classification']\n",
    "                print(f\"   üìä Result: {classification['predicted_label']} \")\n",
    "                print(f\"       Confidence: {classification['confidence']:.3f} ({classification['confidence_level']})\")\n",
    "                print(f\"       Reasoning: {single_result['interpretation']['reasoning'][:100]}...\")\n",
    "            else:\n",
    "                print(f\"   ‚ùå Single article analysis failed: {single_result['error']}\")\n",
    "    \n",
    "    # Step 3: Batch analysis\n",
    "    print(f\"\\nüìÇ Step 3: Batch analysis...\")\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    output_dir = f\"analysis_{timestamp}\"\n",
    "    \n",
    "    batch_results = analyzer.analyze_multiple_articles(test_articles_dir, output_dir)\n",
    "    \n",
    "    if 'error' not in batch_results:\n",
    "        batch_stats = batch_results['batch_statistics']\n",
    "        \n",
    "        print(f\"\\nüìã Step 4: Analysis Summary\")\n",
    "        print(f\"   Total articles processed: {batch_stats['total_articles']}\")\n",
    "        print(f\"   Label distribution:\")\n",
    "        for label, percentage in batch_stats['label_percentages'].items():\n",
    "            count = batch_stats['label_distribution'][label]\n",
    "            print(f\"     {label}: {count} articles ({percentage:.1f}%)\")\n",
    "        \n",
    "        print(f\"   Average confidence: {batch_stats['confidence_statistics']['overall_mean']:.3f}\")\n",
    "        print(f\"   High confidence predictions: {batch_stats['quality_metrics']['high_confidence_count']}\")\n",
    "        \n",
    "        print(f\"\\nüìÅ Output files:\")\n",
    "        print(f\"   Detailed results: {output_dir}/detailed_analysis.json\")\n",
    "        print(f\"   Visual report: {output_dir}/visual_analysis_report.png\")\n",
    "        \n",
    "        return {\n",
    "            'status': 'success',\n",
    "            'batch_results': batch_results,\n",
    "            'output_directory': output_dir\n",
    "        }\n",
    "    else:\n",
    "        print(f\"   ‚ùå Batch analysis failed: {batch_results['error']}\")\n",
    "        return {'error': batch_results['error']}\n",
    "\n",
    "# Example usage demonstration\n",
    "def demonstrate_analysis_system():\n",
    "    \"\"\"\n",
    "    Demonstration of how to use the analysis system.\n",
    "    \n",
    "    This shows the typical workflow for production deployment.\n",
    "    \"\"\"\n",
    "    print(\"üìö Myanmar News Analysis System Demonstration\")\n",
    "    print(\"=\" * 55)\n",
    "    \n",
    "    # Configuration (adjust paths as needed)\n",
    "    model_directory = \"../00_final_model\"  # Directory with trained model\n",
    "    test_articles_directory = \"../data/model_tester/processed\"  # Test articles\n",
    "    \n",
    "    # Check if directories exist\n",
    "    if not os.path.exists(model_directory):\n",
    "        print(f\"‚ùå Model directory not found: {model_directory}\")\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(test_articles_directory):\n",
    "        print(f\"‚ùå Test articles directory not found: {test_articles_directory}\")\n",
    "        return\n",
    "    \n",
    "    # Run the complete analysis\n",
    "    results = run_myanmar_news_analysis(model_directory, test_articles_directory)\n",
    "    \n",
    "    if results.get('status') == 'success':\n",
    "        print(f\"\\n‚úÖ Analysis completed successfully!\")\n",
    "        print(f\"\\nüí° Next steps:\")\n",
    "        print(f\"   1. Review detailed analysis: {results['output_directory']}/detailed_analysis.json\")\n",
    "        print(f\"   2. Examine visual report: {results['output_directory']}/visual_analysis_report.png\")\n",
    "        print(f\"   3. Use individual article results for further processing\")\n",
    "        print(f\"   4. Integrate with production systems as needed\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå Analysis failed. Check error messages above.\")\n",
    "\n",
    "# Uncomment to run demonstration\n",
    "# demonstrate_analysis_system()\n",
    "\n",
    "print(\"‚úÖ Production deployment example complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analysis Interpretation Guide\n",
    "\n",
    "### Understanding Model Outputs\n",
    "\n",
    "**Classification Labels:**\n",
    "- **Neutral (0):** Opposition/neutral perspective, characteristic of DVB News\n",
    "- **Red (1):** Critical/independent perspective, characteristic of Khitthit News  \n",
    "- **Green (2):** Government-friendly perspective, characteristic of Myawady News\n",
    "\n",
    "**Confidence Levels:**\n",
    "- **Very High (‚â•0.8):** Strong confidence, clear stylistic markers\n",
    "- **High (0.6-0.8):** Good confidence, typical language patterns detected\n",
    "- **Medium (0.4-0.6):** Moderate confidence, mixed signals present\n",
    "- **Low (<0.4):** Uncertain classification, article may be atypical\n",
    "\n",
    "**Analysis Quality Indicators:**\n",
    "- **Token Count:** More tokens generally improve accuracy (minimum 20 recommended)\n",
    "- **Myanmar Script Ratio:** Higher Myanmar content typically yields better results\n",
    "- **Relative Confidence:** Large gap between top predictions indicates certainty\n",
    "\n",
    "### Practical Applications\n",
    "\n",
    "**Media Monitoring:**\n",
    "- Track sentiment trends across Myanmar news sources\n",
    "- Identify bias patterns in reporting\n",
    "- Monitor narrative changes over time\n",
    "\n",
    "**Research Applications:**\n",
    "- Analyze political discourse in Myanmar media\n",
    "- Study propaganda and information warfare\n",
    "- Compare government vs. opposition messaging\n",
    "\n",
    "**Quality Assessment:**\n",
    "- High confidence predictions are suitable for automated processing\n",
    "- Medium confidence predictions may need human review\n",
    "- Low confidence predictions require manual verification\n",
    "\n",
    "### Model Limitations\n",
    "\n",
    "**Training Data Constraints:**\n",
    "- Model trained on specific news sources (may not generalize to other outlets)\n",
    "- Historical data (may not reflect current events/language changes)\n",
    "- Limited domain coverage (news articles only)\n",
    "\n",
    "**Technical Limitations:**\n",
    "- Requires Myanmar tokenization (MyWord dependency)\n",
    "- Optimal performance on 100+ token articles\n",
    "- Sensitive to text preprocessing quality\n",
    "\n",
    "**Interpretation Caveats:**\n",
    "- Classifications reflect source bias, not absolute truth\n",
    "- Model detects stylistic patterns, not factual accuracy\n",
    "- Individual articles may deviate from source norms\n",
    "\n",
    "This analysis system provides a powerful tool for understanding Myanmar media landscape through automated sentiment classification with detailed explanations and confidence assessment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}