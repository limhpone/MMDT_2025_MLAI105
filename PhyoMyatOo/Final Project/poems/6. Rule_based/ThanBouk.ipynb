{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "343370ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# ==============================================================================\n",
    "# The Final, Grammatically Precise Tokenizer for Clean Syllables\n",
    "# This is used in Step 2 of the main function below.\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# The Main \"Syllable Splitter\" Function\n",
    "# ==============================================================================\n",
    "def custom_syllable_splitter(text: str) -> list:\n",
    "    \"\"\"\n",
    "    Performs a deep syllable split by breaking down all consonant stacks.\n",
    "    This function uses a two-step process to achieve the required logic for\n",
    "    cases like 'á€”á€€á€¹á€á€á€¹á€' and 'á€¥á€€á€¹á€€á€‹á€¹á€Œ'.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # --- Step 1: Pre-processing to split stacks using a loop ---\n",
    "    # This loop is the only reliable way to handle chained stacks.\n",
    "    stacked_consonant_pattern = r'([á€€-á€¡])(á€º?á€¹)([á€€-á€¡])'\n",
    "    processed_text = text\n",
    "    while re.search(stacked_consonant_pattern, processed_text):\n",
    "        processed_text = re.sub(stacked_consonant_pattern, r'\\1á€º'  + r'\\3', processed_text)\n",
    "    processed_text = re.sub(r\"(([A-Za-z0-9]+)|[á€€-á€¡|á€¥|á€¦](á€„á€ºá€¹|[á€€-á€¡|á€¥][á€¾]*[á€·á€¸]*[á€º]|á€¹[á€€-á€¡]|[á€«-á€¾á‚ê©»][ê©»]*){0,}|.)\",r\"\\1 \", processed_text)\n",
    "    print()\n",
    "   #Step 2: Tokenization of the processed parts ---\n",
    "   # The string is now clean of stacks, so we can tokenize it reliably.\n",
    "    final_list = processed_text.split(\" \")\n",
    "    \n",
    "    # Filter out empty strings caused by trailing spaces\n",
    "    final_list = [word for word in final_list if word.strip()]\n",
    "        \n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bc13480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of all Burmese consonants (including the great 'á€¡')\n",
    "# This is used to distinguish consonants from vowels/diacritics.\n",
    "# --- Constants ---\n",
    "BURMESE_CONSONANTS = \"á€€á€á€‚á€ƒá€„á€…á€†á€‡á€ˆá€Šá€‹á€Œá€á€á€á€á€‘á€’á€“á€”á€•á€–á€—á€˜á€™á€šá€›á€œá€á€á€Ÿá€ á€¡\"\n",
    "# Consonantal medials (part of the onset)\n",
    "CONSONANTAL_MEDIALS = \"á€»á€¼á€¾á€½\" \n",
    "\n",
    "# --- The Rhyme Group Normalization Map ---\n",
    "# This is the heart of the logic. It maps an entire spelled rime\n",
    "# to its canonical phonetic group. This is robust and easy to extend.\n",
    "# Key: Orthographic (spelled) rime\n",
    "# Value: Normalized phonetic rime for comparison\n",
    "RIME_NORMALIZATION_MAP = {\n",
    "    # -at sound (á€¡á€€á€º)\n",
    "    \"á€á€º\": \"á€€á€º\", \"á€•á€º\": \"á€€á€º\",  \n",
    "    # -it sound (á€¡á€­á€€á€º)\n",
    "    \"á€­á€á€º\": \"á€­á€€á€º\", \"á€­á€•á€º\": \"á€­á€€á€º\", \"á€­á€…á€º\": \"á€­á€€á€º\",\n",
    "    # -ut sound (á€¡á€¯á€á€º)\n",
    "    \"á€¯á€á€º\": \"á€¯á€•á€º\",\n",
    "    # -et sound (á€¡á€€á€º) - Note: different vowel from -at, but uses same final\n",
    "    \"á€€á€º\": \"á€€á€º\",\n",
    "    \n",
    "    # -an sound (á€¡á€”á€º)\n",
    "    \"á€™á€º\": \"á€”á€º\",\n",
    "    # -in sound (á€¡á€­á€”á€º)\n",
    "    \"á€­á€™á€º\": \"á€­á€”á€º\",\n",
    "    # -un sound (á€¡á€¯á€”á€º)\n",
    "    \"á€¯á€”á€º\": \"á€­á€”á€º\", # This can sometimes be phonetic, though less common\n",
    "    \n",
    "    # Special finals\n",
    "    \"á€‰á€º\": \"á€”á€º\", # Sounds like -an\n",
    "    \"á€Šá€º\": \"á€šá€º\", # Sounds like -ay\n",
    "\n",
    "    \"á€šá€·á€º\":\"á€²á€·\"\n",
    "}\n",
    "\n",
    "\n",
    "def _get_onset_length(word: str) -> int:\n",
    "    \"\"\"Finds the length of the initial consonant cluster (onset).\"\"\"\n",
    "    if not word or word[0] not in BURMESE_CONSONANTS:\n",
    "        return 0\n",
    "    \n",
    "    onset_len = 1\n",
    "    # Greedily consume any following consonantal medials\n",
    "    while onset_len < len(word) and word[onset_len] in CONSONANTAL_MEDIALS:\n",
    "        onset_len += 1\n",
    "    return onset_len\n",
    "\n",
    "# --- The Main Rhyme Function ---\n",
    "def get_rhyme_group(word: str) -> str:\n",
    "    \"\"\"\n",
    "    Finds the phonetically normalized rhyme part of a Burmese word.\n",
    "    \n",
    "    This function correctly isolates the rime (vowel + final) and normalizes it\n",
    "    according to Burmese poetic rules (á€€á€¬á€›á€”á€ºá€á€‚á€º), ensuring both the\n",
    "    vowel and final consonant sound group are respected.\n",
    "    \"\"\"\n",
    "    # 1. Isolate the rime by stripping the onset.\n",
    "    onset_len = _get_onset_length(word)\n",
    "    rime = word[onset_len:]\n",
    "    rime = rime.replace('á€«', 'á€¬')\n",
    "\n",
    "\n",
    "    if not rime:\n",
    "        return \"\"\n",
    "    \n",
    "    # 2. Normalize the rime using the map.\n",
    "    # If the rime is in our map, return its canonical value. Otherwise, return the rime itself.\n",
    "    return RIME_NORMALIZATION_MAP.get(rime, rime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6616080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "ğŸ“œ Analyzing Poem:\n",
      "\n",
      "------------------------------\n",
      "âœ… Rule Passed: Poem has 3 lines.\n",
      "\n",
      "\n",
      "\n",
      "âœ… Rule Passed: Line 1 has 4 words.\n",
      "âœ… Rule Passed: Line 2 has 3 words.\n",
      "âœ… Rule Passed: Line 3 has 5 words (which is 5 or 7).\n",
      "  - Rhyme part for 'á€•á€¼': ''\n",
      "  - Rhyme part for 'á€€': ''\n",
      "  - Rhyme part for 'á€á€»': ''\n",
      "\n",
      "âœ… Rule Passed: The 4-3-2 rhyme scheme is correct.\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def check_than_bauk(poem: str):\n",
    "    \"\"\"\n",
    "    Analyzes a given poem to check if it follows the rules of Than-Bauk.\n",
    "    \"\"\"\n",
    "    print(\"-\" * 30)\n",
    "    print(\"ğŸ“œ Analyzing Poem:\\n\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # 1. Preprocessing: Split into lines and words\n",
    "    # Filter out any empty lines that might result from extra newlines\n",
    "    lines = [line.strip() for line in poem.strip().split('\\n') if line.strip()]\n",
    "\n",
    "    # --- Rule 1: Check for 3 lines ---\n",
    "    if len(lines) != 3:\n",
    "        print(f\"âŒ Rule Failed: A Than-Bauk must have exactly 3 lines. (Found: {len(lines)})\")\n",
    "        print(\"-\" * 30)\n",
    "        return\n",
    "\n",
    "    print(\"âœ… Rule Passed: Poem has 3 lines.\")\n",
    "    words_by_line = [custom_syllable_splitter(line) for line in lines]\n",
    "    # --- Rule 2: Check word counts per line ---\n",
    "    all_word_counts_valid = True\n",
    "    \n",
    "    # Line 1 word count\n",
    "    if len(words_by_line[0]) == 4:\n",
    "        print(f\"âœ… Rule Passed: Line 1 has 4 words.\")\n",
    "    else:\n",
    "        print(f\"âŒ Rule Failed: Line 1 must have 4 words. (Found: {len(words_by_line[0])})\")\n",
    "        all_word_counts_valid = False\n",
    "        \n",
    "    # Line 2 word count\n",
    "    if len(words_by_line[1]) == 3:\n",
    "        print(f\"âœ… Rule Passed: Line 2 has 3 words.\")\n",
    "    else:\n",
    "        print(f\"âŒ Rule Failed: Line 2 must have 3 words. (Found: {len(words_by_line[1])})\")\n",
    "        all_word_counts_valid = False\n",
    "        \n",
    "    # Line 3 word count\n",
    "    if len(words_by_line[2]) in [5, 7]:\n",
    "        print(f\"âœ… Rule Passed: Line 3 has {len(words_by_line[2])} words (which is 5 or 7).\")\n",
    "    else:   \n",
    "        print(f\"âŒ Rule Failed: Line 3 must have 5 or 7 words. (Found: {len(words_by_line[2])})\")\n",
    "        all_word_counts_valid = False\n",
    "        \n",
    "    # If word counts are wrong, we can't reliably check rhymes, so we stop.\n",
    "    if not all_word_counts_valid:\n",
    "        print(\"\\nâš ï¸ Cannot check rhyme scheme due to incorrect word counts.\")\n",
    "        print(\"-\" * 30)\n",
    "        return\n",
    "\n",
    "    # --- Rule 3: Check Rhyme Scheme (4-3-2) ---\n",
    "    try:\n",
    "        word1_4 = words_by_line[0][3] # 4th word of 1st line\n",
    "        word2_3 = words_by_line[1][2] # 3rd word of 2nd line\n",
    "        word3_2 = words_by_line[2][1] # 2nd word of 3rd line\n",
    "        \n",
    "      \n",
    "\n",
    "        rhyme1 = get_rhyme_group(word1_4)\n",
    "        rhyme2 = get_rhyme_group(word2_3)\n",
    "        rhyme3 = get_rhyme_group(word3_2)\n",
    "        \n",
    "        print(f\"  - Rhyme part for '{word1_4}': '{rhyme1}'\")\n",
    "        print(f\"  - Rhyme part for '{word2_3}': '{rhyme2}'\")\n",
    "        print(f\"  - Rhyme part for '{word3_2}': '{rhyme3}'\")\n",
    "\n",
    "        if rhyme1 == rhyme2 == rhyme3:\n",
    "            print(\"\\nâœ… Rule Passed: The 4-3-2 rhyme scheme is correct.\")\n",
    "        else:\n",
    "            print(\"\\nâŒ Rule Failed: The words do not rhyme correctly.\")\n",
    "\n",
    "    except IndexError:\n",
    "        # This should not happen if word count checks passed, but it's good practice\n",
    "        print(\"\\nâŒ Error: Could not extract rhyming words. Check line structure.\")\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# --- Examples to Test ---\n",
    "\n",
    "# Example 1: A perfect Than-Bauk (by LedÄ« SayÄdaw)\n",
    "# Rhyme words: á€€á€±á€¬á€„á€ºá€¸, á€œá€±á€¬á€„á€ºá€¸, á€…á€±á€¬á€„á€ºá€¸\n",
    "poem_correct = \"\"\"\n",
    "á€á€­á€¯á€¸á€á€¬á€¸á€‘á€¬á€¸á€•á€¼\n",
    "á€Ÿá€°á€á€¯á€¶á€€\n",
    "á€™á€¯á€á€»á€€á€¼á€±á€¬á€€á€ºá€¡á€•á€ºá€…á€½á€¬\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    check_than_bauk(poem_correct)\n",
    "   \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35a79e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now you can try your own!\n",
      "Paste your 3-line poem below and press Enter twice to finish.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nNow you can try your own!\")\n",
    "print(\"Paste your 3-line poem below and press Enter twice to finish.\")\n",
    "\n",
    "user_input_lines = []\n",
    "while True:\n",
    "    try:\n",
    "        line = input()\n",
    "        if not line:\n",
    "            break\n",
    "        user_input_lines.append(line)\n",
    "    except EOFError:\n",
    "        break\n",
    "        \n",
    "user_poem = \"\\n\".join(user_input_lines)\n",
    "if user_poem:\n",
    "    check_than_bauk(user_poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330e5d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4801742b",
   "metadata": {},
   "source": [
    "\"áá‹ á€á€­á€¯á€¸á€á€¬á€¸á€‘á€¬á€¸á€•á€¼áŠ á€Ÿá€°á€á€¯á€¶á€€áŠ á€™á€¯á€á€»á€€á€¼á€±á€¬á€€á€ºá€¡á€•á€ºá€…á€½á€¬á‹\n",
    "\n",
    "á‚á‹ á€€á€­á€¯á€šá€ºá€á€½á€„á€ºá€¸á€á€°á€á€­á€¯á€¸áŠ á€™á€¼á€„á€ºá€á€°á€á€­á€¯á€¸áŠ á€”á€¾á€…á€ºá€™á€»á€­á€¯á€¸á€™á€¾á€á€ºá€€á€¼á€›á€¬á‹\n",
    "\n",
    "áƒá‹ á€€á€­á€¯á€šá€ºá€á€½á€„á€ºá€¸á€‘á€¬á€¸á€•á€¼áŠ á€•á€¼á€„á€ºá€‘á€¬á€¸á€•á€¼áŠ á€”á€¾á€…á€ºá€á€›á€¾á€­á€á€Šá€ºá€á€¬á‹\n",
    "\n",
    "á„á‹ á€€á€­á€¯á€šá€ºá€á€½á€„á€ºá€¸á€›á€”á€ºá€á€°áŠ á€•á€¼á€„á€ºá€›á€”á€ºá€á€°áŠ á€”á€¾á€…á€ºá€™á€°á€á€½á€²á€›á€¾á€¯á€›á€¬á‹\n",
    "\n",
    "á…á‹ á€•á€¼á€„á€ºá€•á€œá€°á€‘á€€á€ºáŠ á€€á€­á€¯á€šá€ºá€á€½á€„á€ºá€¸á€á€€á€ºáŠ á€†á€€á€ºá€†á€€á€ºá€á€­á€¡á€•á€ºá€…á€½á€¬á‹\n",
    "\n",
    "á†á‹ á€€á€­á€¯á€šá€ºá€á€½á€„á€ºá€¸á€á€­á€¯á€¸á€á€¬á€¸áŠ á€œá€€á€ºá€á€¶á€‘á€¬á€¸áŠ á€•á€¼á€„á€ºá€á€­á€¯á€¸á€á€¬á€¸á€á€½á€± á€™á€½á€¾á€±á€œá€­á€™á€·á€ºá€™á€Šá€ºá‹\n",
    "\n",
    "á‡á‹ á€€á€­á€¯á€šá€ºá€á€½á€„á€ºá€¸á€‘á€¬á€¸á€•á€¼áŠ á€œá€€á€ºá€á€¶á€€á€¼áŠ á€•á€¼á€„á€ºá€€á€‘á€¬á€¸á€•á€¼-á€á€»á€±á€œá€­á€™á€·á€ºá€™á€Šá€ºá‹\n",
    "\n",
    "áˆá‹ á€€á€­á€¯á€šá€ºá€á€½á€„á€ºá€¸á€›á€”á€ºá€á€°áŠ á€œá€€á€ºá€á€¶á€™á€°áŠ á€•á€¼á€„á€ºá€›á€”á€ºá€á€°á€€á€¼á€±á€¬á€„á€·á€º- á€á€±á€œá€­á€™á€·á€ºá€™á€Šá€ºá‹ \"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
